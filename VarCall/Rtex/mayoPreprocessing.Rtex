%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Analysis of BRCA2 MAVE Data.      %%
%%  Combine NCI and Mayo Studies.    %%
%%  Mayo Data Preprocessing Step.    %%
%%     Annotated knitr doc           %%
%% Last Modified  11/15/24 by ESI.   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass{article}

%% begin.rcode setup, include=FALSE
% opts_chunk$set(fig.path='./figs/',cache.path='./cache/',child.path='../')
%% end.rcode

\input{../preamble.tex}

\title{2024 BRCA2 VuS Joint Analysis of Mayo and NCI MAVE
  Data\\ Mayo Clinic Data Preprocessing Script}
%\author{Author1, Author2, Author3}
\date{\today}
\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle

\section{High--Level User--Specified Parameters}

%% begin.rcode
%  ## Do you want a test run with a 20% Subset?
%  subst<-FALSE
%  ## Choose Data Set:
%  ## db<-"uvCounts"
%  db<-"uvCountsFnl"
%  ##
%% end.rcode

\section{Start Up}

Set a seed for the random number generators to ensure repeatabability
and load necessary R libraries.

%% begin.rcode
%  ## Set Random Seed
%  set.seed(seed=03122024)
%  ## Load custom functions that will be used below:
%  source("../RFuncs.R",echo=FALSE)
%  ## Libraries:
%  library(mgcv)
%% end.rcode

\section{Import and Process Mayo Clinic Data}

Read in the MAVE data and training variant labels:

%% begin.rcode
%  if (db=="uvCounts"){
%    uvDB<-read.delim("../combined.tsv")
%  }
%  if (db=="uvCountsFnl"){
%    uvDB<-read.delim("../combined.raw.tsv")
%  }
%  dim(uvDB)
%  if (subst==TRUE) uvDB<-uvDB[seq(1,nrow(uvDB),by=5),]
%  dim(uvDB)
%  ## use StopGain vs Synonymous for Training lables:
%  newTrainingLabel<-read.csv("../variant_type_for_train.csv")
%  kdel<-unique(newTrainingLabel$uPOS[newTrainingLabel$EventType=="StopGain"])
%  kneut<-unique(newTrainingLabel$uPOS[newTrainingLabel$EventType=="Synonymous"])
%  uvDB$label<-rep(NA,nrow(uvDB))
%  uvDB$label[uvDB$uPOS %in% kdel]<-"P"
%  uvDB$label[uvDB$uPOS %in% kneut]<-"B"
%  head(uvDB)
%% end.rcode

\subsection{DB Row Column Names}

Add row names; change a few column names; make `Exon' a factor:

%% begin.rcode
%  if ((db=="uvCounts")|(db=="uvCountsFnl")){
%     colnames(uvDB)[colnames(uvDB)=="class"]<-"classification"
%     colnames(uvDB)[colnames(uvDB)=="exon"]<-"Exon"
%     colnames(uvDB)[colnames(uvDB)=="PB"]<-"P_B"
%     ## Annotation DB:
%     annot<-uvDB[,c(1:23,42:43)]
%  }
%  if (nrow(uvDB)==length(unique(uvDB$uPOS))) rownames(uvDB)<-uvDB$uPOS
%  uvDB$Exon<-factor(uvDB$Exon)
%% end.rcode

\subsection{Compute Offsets and Other Summaries for Counts Data}

Compute count totals for all observed combintations of day, exon and
replicate (labeled `offsets' in the code below), then use these to
compute raw abundance rates (denoted $A_{v,r,d}$ in the
Supplement). Use the abundance rates to compute day 14 to day 5 and
day 14 to day 0 (lib) rate ratios (denoted $R_{v,r}^{14:5}$ and
$R_{v,r}^{14:0}$, respectively, in the Supplement).  Add columns
containing the `offsets' and the two rate ratios to the working data
base {\texttt{uvDB}}.  Finally, compute an exon--specific standardized
position variable {\texttt{PosStd}} and add it to the working data
base.

%% begin.rcode
% if ((db=="uvCounts")|(db=="uvCountsFnl")){
%   cnames<-colnames(uvDB)
%   lcnames<-nchar(cnames)
%   daylib<-cnames[substr(cnames,lcnames-2,lcnames)=="lib"]
%   day5<-cnames[substr(cnames,lcnames-1,lcnames)=="D5"]
%   day14<-cnames[substr(cnames,lcnames-2,lcnames)=="D14"]
%   offsetlib<-matrix(NA,nrow(uvDB),length(daylib))
%   colnames(offsetlib)<-cnOffsetLib<-paste0("R",1:6,"offsetLib")
%   offset5<-matrix(NA,nrow(uvDB),length(day5))
%   colnames(offset5)<-cnOffset5<-paste0("R",1:6,"offsetD5")
%   offset14<-matrix(NA,nrow(uvDB),length(day14))
%   colnames(offset14)<-cnOffset14<-paste0("R",1:6,"offsetD14")
%   for (i in 1:length(day5)){
%       templib<-lapply(split(uvDB[,daylib[i]],uvDB$Exon),sum,na.rm=TRUE)
%       temp5<-lapply(split(uvDB[,day5[i]],uvDB$Exon),sum,na.rm=TRUE)
%       temp14<-lapply(split(uvDB[,day14[i]],uvDB$Exon),sum,na.rm=TRUE)
%       offsetlib[,i]<-as.numeric(templib[uvDB$Exon])
%       offset5[,i]<-as.numeric(temp5[uvDB$Exon])
%       offset14[,i]<-as.numeric(temp14[uvDB$Exon])
%   }
%   rawlib<-(uvDB[,daylib]/offsetlib)  ## lib (day 0) abundance rates
%   raw5<-(uvDB[,day5]/offset5)        ## day 5 abundance rates
%   raw14<-(uvDB[,day14]/offset14)     ## day 14 abundance rates
%   raw<-(raw14/raw5)                  ## day 14 to day 5 rate ratio
%   raw2<-(raw14/rawlib)               ## day 15 to day 0 rate ratio
%   colnames(raw)<-paste0("R",1:6,"_raw")
%   colnames(raw2)<-paste0("R",1:6,"_rawlib")
%   uvDB<-cbind(uvDB,offsetlib,offset5,offset14,raw,raw2)
%   rm(offsetlib,offset5,offset14,lcnames,raw,raw2,rawlib,raw5,raw14)
%   pos.min<-lapply(split(uvDB[,"POS"],uvDB$Exon),min,na.rm=TRUE)
%   pos.max<-lapply(split(uvDB[,"POS"],uvDB$Exon),max,na.rm=TRUE)
%   pos.range<- as.numeric(pos.max) - as.numeric(pos.min)
%   names(pos.range)<-names(pos.min)
%   uvDB$PosMin<-as.numeric(pos.min[uvDB$Exon])
%   uvDB$PosMax<-as.numeric(pos.max[uvDB$Exon])
%   uvDB$PosRange<-as.numeric(pos.range[uvDB$Exon])
%   uvDB$PosStd<-((uvDB$POS - uvDB$PosMin)/(uvDB$PosMax - uvDB$PosMin))
%   summary(uvDB$PosStd)
% }
%% end.rcode


\section{Exploratory Data Analysis}

\subsection{Tabular Summaries}

Cross--tabulations of several design and annotation variables:

%% begin.rcode
%  table(uvDB$Exon,uvDB$EventType,useNA="always")
%  table(uvDB$Exon,uvDB$P_B,useNA="always")
%  ##table(uvDB$EventType,uvDB$spliceR,useNA="always")
%  table(uvDB$P_B,uvDB$classification)
%  table(uvDB$label,uvDB$classification)
%  ##table(uvDB$EventType,uvDB$spliceR)
%  table(uvDB$EventType,uvDB$classification)
%% end.rcode

\newpage
\subsection{Graphical Summaries of Labeled Data}

Histograms of: (1) the replicate 1 day 14 to day 5 rate ratio, (2) the
median day 14 to day 5 rate ratio across replicates and (3) the median
day 14 to day 0 (not yet positionally normalized) rate ratio.

%% begin.rcode, fig.width=7.5, fig.height=9.5
%  par(mfrow=c(3,1))
%  plot(c(0,3.5),c(0,2.5),las=1,xlab="R1_Raw",ylab="Probability",type="n",
%      ,main="Histogram of Labelled Rep1 D14/D5 Ratios by Class")
%  hist(uvDB$R1_raw[(!is.na(uvDB$P_B))&(uvDB$P_B=="B")],
%       col=3,prob=TRUE,nclass=30,add=TRUE)
%  hist(uvDB$R1_raw[(!is.na(uvDB$P_B))&(uvDB$P_B=="P")],
%       col=2,prob=TRUE,nclass=30,add=TRUE)
%  legend("topleft",inset=0.05,legend=c("Benign","Pathogenic"),
%         col=c(3,2),lwd=5)
%  ## Median of Raw D14/D5 Ratios:
%  uvDB$rawMedn<-apply(uvDB[,c("R1_raw","R2_raw","R3_raw","R4_raw","R5_raw","R6_raw")],
%                        1,FUN=median,na.rm=TRUE)
%  plot(c(0,3.5),c(0,2.5),las=1,xlab="rawMedn",ylab="Probability",type="n",
%      ,main="Histogram of Labelled Raw Median D14/D5 Ratios by Class")
%  hist(uvDB$rawMedn[(!is.na(uvDB$P_B))&(uvDB$P_B=="B")],
%       col=3,prob=TRUE,nclass=30,add=TRUE)
%  hist(uvDB$rawMedn[(!is.na(uvDB$P_B))&(uvDB$P_B=="P")],
%       col=2,prob=TRUE,nclass=30,add=TRUE)
%  legend("topleft",inset=0.05,legend=c("Benign","Pathogenic"),
%         col=c(3,2),lwd=5)
%  ## Median of Raw Day14/lib Ratios 
%  uvDB$rawLibMedn<-apply(uvDB[,c("R1_rawlib","R2_rawlib","R3_rawlib","R4_rawlib",
%                                 "R5_rawlib","R6_rawlib")],
%                          1,FUN=median,na.rm=TRUE)
%  plot(c(0,3.5),c(0,2.5),las=1,xlab="ceNormMedn",ylab="Probability",type="n",
%      ,main="Histogram of Labelled Day14/Lib Median Ratios by Class")
%  hist(uvDB$rawLibMedn[(!is.na(uvDB$P_B))&(uvDB$P_B=="B")],
%       col=3,prob=TRUE,nclass=30,add=TRUE)
%  hist(uvDB$rawLibMedn[(!is.na(uvDB$P_B))&(uvDB$P_B=="P")],
%       col=2,prob=TRUE,nclass=30,add=TRUE)
%  legend("topleft",inset=0.05,legend=c("Benign","Pathogenic"),
%         col=c(3,2),lwd=5)
%% end.rcode

\newpage
\section{Create `Tall' Data Structure}

Here we create a stacked data structure with day-- and
replicate--specific measurments in different rows and the variant
counts and batch totals (`offsets') each in their own column.  This
format is needed modeling.  Save the old {\texttt{uvDB}} as
{\texttt{uvMaster}} and save the stacked data structure as the new
{\texttt{uvDB}}. Convert categorical variables from character to
factor types.

%% begin.rcode
%  uvMaster<-uvDB
%  uvDB<-uvDB[,c("uPOS","PosStd","Exon","P_B","label","EventType",day5,day14,daylib,cnOffset5,cnOffset14,cnOffsetLib)]
%  rownames(uvDB)<-NULL
%  temp<-uvDB
%  n<-nrow(temp)
%  tall<-NULL
%  for (i in 1:6){
%    replic<-paste0("R",i)
%    d5<-cbind(as.matrix(temp[,c("uPOS","PosStd","Exon","P_B","label","EventType",day5[i],cnOffset5[i])]),
%              rep("D5",n),rep(replic,n))
%    d14<-cbind(as.matrix(temp[,c("uPOS","PosStd","Exon","P_B","label","EventType",day14[i],cnOffset14[i])]),
%              rep("D14",n),rep(replic,n))
%    d0<-cbind(as.matrix(temp[,c("uPOS","PosStd","Exon","P_B","label","EventType",daylib[i],cnOffsetLib[i])]),
%              rep("D0",n),rep(replic,n))
%    colnames(d0)<-colnames(d5)<-colnames(d14)<-NULL
%    tall<-rbind(tall,d0,d5,d14)
%  }
%  uvDB<-data.frame(tall)
%  rm(temp)
%  colnames(uvDB)<-c("variant","PosStd","Exon","p.b","label","eventtype","count","offset","day","replicate")
%  uvDB$PosStd<-as.numeric(uvDB$PosStd)
%  uvDB$count<-as.numeric(uvDB$count)
%  uvDB$offset<-as.numeric(uvDB$offset)
%  uvDB<-uvDB[!is.na(uvDB$count),]
%  uvDB$day<-factor(uvDB$day)
%  uvDB$replicate<-factor(uvDB$replicate)
%  uvDB$variant<-factor(uvDB$variant)
%  uvDB$Exon<-factor(uvDB$Exon)
%  uvDB$p.b<-factor(uvDB$p.b)
%  uvDB$p.b<-factor(uvDB$label)
%  uvDB$batchE<-as.numeric(uvDB$Exon)   ## batch=exon
%  ## Exon by Rep
%  uvDB$ER<-paste0(substr(uvDB$Exon,1,4),uvDB$replicate)
%  uvDB$ER<-factor(uvDB$ER)
%  uvDB$batch<-as.numeric(uvDB$ER)  ## More refined batch variable
%  table(uvDB$ER)
%  table(uvDB$batch)
%  head(uvDB)
%  summary(uvDB)
%%  end.rcode

\newpage
\section{Positional Normalization}

Computations in support of the positional normalization of the day 0
(lib) counts to the day 5 values.  Two methods for computing the
positional correction are implemented here: by exon and by exon and
replicate.  We use the latter approach; the former is not used.

\subsubsection{Data Processing}

Create a data structure ({\texttt{uvNorm}}) for the normalization
model.  Compute the day 5 to day 0 rate ratio $R^{5:0}$ for the model
and subset to variants such that $R^{5:0} \,>\,0.5$ or $R^{14:5}
\,>\,0.8$.

%% begin.rcode
%  tall<-data.frame(tall)
%  colnames(tall)<-c("variant","PosStd","Exon","p.b","label","eventtype","count","offset","day","replicate")
%  ## Exon by Rep
%  tall$ER<-paste0(substr(tall$Exon,1,4),tall$replicate)
%  table(tall$ER)
%  table(tall$eventtype)
%  table(tall$day)
%  uvD0<-tall[tall$day=="D0",]
%  uvD5<-tall[tall$day=="D5",]
%  uvD14<-tall[tall$day=="D14",]
%  table((uvD0$variant==uvD5$variant)&(uvD0$Exon==uvD5$Exon)&(uvD0$replicate==uvD5$replicate))
%  table((uvD14$variant==uvD5$variant)&(uvD14$Exon==uvD5$Exon)&(uvD14$replicate==uvD5$replicate))
%  uvD0$rawR<-(as.numeric(uvD0$count)/as.numeric(uvD0$offset))
%  uvD5$rawR<-(as.numeric(uvD5$count)/as.numeric(uvD5$offset))
%  uvD14$rawR<-(as.numeric(uvD14$count)/as.numeric(uvD14$offset))
%  uvD5$R14.5<-(uvD14$rawR/uvD5$rawR)
%  uvD5$R5.0<-(uvD5$rawR/uvD0$rawR)
%  R14.5<-lapply(split(uvD5[,"R14.5"],uvD5$variant),mean,na.rm=TRUE)
%  R14.5<-unlist(R14.5)
%  R5.0<-lapply(split(uvD5[,"R5.0"],uvD5$variant),mean,na.rm=TRUE)
%  R5.0<-unlist(R5.0)
%  table(names(R14.5)==names(R5.0))
%  ## Subset of Variants to Use for Positional Normalization of Lib Values
%  posTrainVariants<-names(R5.0)[(R14.5>0.8)|(R5.0>0.5)]
%  length(posTrainVariants)
%  keep<-(uvD5$variant %in% posTrainVariants)
%  ## Ratio for Positional Normalization Analysis:
%  uvD5$Ratio<-(as.numeric(uvD5$count)/as.numeric(uvD5$offset))
%  uvD5$Ratio<-uvD5$Ratio/(as.numeric(uvD0$count)/as.numeric(uvD0$offset))
%  summary(uvD5$Ratio)
%  ##keep<-((uvD5$eventtype=="Synonymous")|(uvD5$eventtype=="Missense"))
%  keep<-(keep&(!is.na(uvD5$Ratio)))
%  uvNorm<-uvD5[keep,]
%  uvNorm$Exon<-as.factor(uvNorm$Exon)
%  uvNorm$PosStd<-as.numeric(uvNorm$PosStd)
%  uvNorm$lRatio<-log(uvNorm$Ratio)
%% end.rcode

\subsubsection{Normalization By Exon, Combining Replicates (Not Used)}

Implement the exon--by--exon normalization scheme and generate
plots of the data and the estimated positional normalization curve.

%% begin.rcode, posFit1-cache, cache=TRUE, cache.lazy=FALSE
%   gam.pos<-mgcv::gam(lRatio ~  s(PosStd,bs="ad",by=Exon),data=uvNorm)
%   gam.pos2<-mgcv::gam(lRatio ~ s(PosStd,bs="tp",by=Exon),data=uvNorm)
%   temp<-predict(gam.pos,newdata=uvNorm,se.fit=TRUE)
%   uvNorm$adSmooth<-temp$fit
%   uvNorm$adSmoothSE<-temp$se.fit 
%   temp<-predict(gam.pos2,newdata=uvNorm,se.fit=TRUE)
%   uvNorm$tpSmooth<-temp$fit
%   uvNorm$tpSmoothSE<-temp$se.fit
%   posFits<-unique(uvNorm[,c("variant","Exon","PosStd","adSmooth","adSmoothSE",
%                             "tpSmooth","tpSmoothSE")])
%   uExon<-unique(as.character(uvNorm$Exon))
%   nExon<-length(uExon)
%   pdf("SmoothFitsFnl.pdf",height=8.5,width=11)
%   par(mfrow=c(2,1))
%   ## Adaptive Smoooth
%   for (i in 1:nExon){
%   plot(uvNorm$PosStd[uvNorm$Exon==uExon[i]],
%        uvNorm$lRatio[uvNorm$Exon==uExon[i]],las=1,
%        ylab="logRatio",xlab="Standardized Position",
%        main=paste0("Adaptive Smooth Fit to Exon ",uExon[i]),xlim=c(0,1.12))
%   uRep<-unique(uvNorm$replicate[(uvNorm$Exon==uExon[i])])
%   for (j in 1:length(uRep)){
%     points(uvNorm$PosStd[(uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j])],
%          uvNorm$lRatio[(uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j])],
%          col=j,pch=16)
%   }
%   ##points(uvNorm$PosStd[(uvNorm$Exon==uExon[i])&(uvNorm$eventtype=="Synonymous")],
%   ##     uvNorm$lRatio[(uvNorm$Exon==uExon[i])&(uvNorm$eventtype=="Synonymous")],
%   ##     col=3,pch=16)
%   legend("topright",inset=0.01,col=c(1:length(uRep)),lwd=5,legend=uRep)
%   ##legend("topright",inset=0.05,col=c(1,3),lwd=5,legend=c("Missense","Synonymous"))
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$adSmooth[posFits$Exon==uExon[i]],col=2,lwd=3)
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$adSmooth[posFits$Exon==uExon[i]]+2*posFits$adSmoothSE[posFits$Exon==uExon[i]],
%         col=2,lwd=3,lty=2)
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$adSmooth[posFits$Exon==uExon[i]]-2*posFits$adSmoothSE[posFits$Exon==uExon[i]],
%         col=2,lwd=3,lty=2)
%   ## Thin Plate Smoooth
%   plot(uvNorm$PosStd[uvNorm$Exon==uExon[i]],
%        uvNorm$lRatio[uvNorm$Exon==uExon[i]],las=1,
%        ylab="logRatio",xlab="Standardized Position",
%        main=paste0("Thin Plate Smooth Fit to Exon ",uExon[i]),
%        type="n",xlim=c(0,1.12))
%   for (j in 1:length(uRep)){
%     points(uvNorm$PosStd[(uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j])],
%          uvNorm$lRatio[(uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j])],
%          col=j,pch=16)
%   }
%   ##points(uvNorm$PosStd[(uvNorm$Exon==uExon[i])&(uvNorm$eventtype=="Synonymous")],
%   ##     uvNorm$lRatio[(uvNorm$Exon==uExon[i])&(uvNorm$eventtype=="Synonymous")],
%   ##     col=3,pch=16)
%   legend("topright",inset=0.01,col=c(1:length(uRep)),lwd=5,legend=uRep)
%   ##legend("topright",inset=0.05,col=c(1,3),lwd=5,legend=c("Missense","Synonymous"))
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$tpSmooth[posFits$Exon==uExon[i]],col=2,lwd=3)
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$tpSmooth[posFits$Exon==uExon[i]]+2*posFits$tpSmoothSE[posFits$Exon==uExon[i]],
%         col=2,lwd=3,lty=2)
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$tpSmooth[posFits$Exon==uExon[i]]-2*posFits$tpSmoothSE[posFits$Exon==uExon[i]],
%         col=2,lwd=3,lty=2)
%   }
%   dev.off()
%% end.rcode

\subsubsection{Normalization By Exon and Replicate (This Method Used)}

Implement the exon by replicate normalization scheme and generate
plots of the data and the estimated positional normalization curve.

%% begin.rcode, posFit2-cache, cache=TRUE, cache.lazy=FALSE
%   uvNorm$adSmooth<-rep(NA,nrow(uvNorm))
%   uvNorm$adSmoothSE<-rep(NA,nrow(uvNorm))
%   uvDB$adSmooth<-rep(NA,nrow(uvDB))
%   uvDB$adSmoothSE<-rep(NA,nrow(uvDB))
%   pdf("SmoothFitsByRepFnl.pdf",height=8.0,width=24)
%   par(mfrow=c(1,1))
%   ## Adaptive Smoooth -- Independent Fits by Exon and Replicate
%   for (i in 1:nExon){
%       plot(uvNorm$PosStd[uvNorm$Exon==uExon[i]],
%            uvNorm$lRatio[uvNorm$Exon==uExon[i]],las=1,
%            ylab="logRatio",xlab="Standardized Position",
%            main=paste0("Replicate-Specific Adaptive Smooth Fit to Exon ",uExon[i]),
%            xlim=c(0,1.12))
%       uRep<-unique(uvNorm$replicate[(uvNorm$Exon==uExon[i])])  ##unique replicate IDs
%       for (j in 1:length(uRep)){
%           keep<-((uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j]))
%           gam.pos<-mgcv::gam(lRatio ~  s(PosStd,bs="ad",by=Exon),data=uvNorm[keep,])
%           temp<-predict(gam.pos,newdata=uvNorm[keep,],se.fit=TRUE)
%           uvNorm$adSmooth[keep]<-temp$fit
%           uvNorm$adSmoothSE[keep]<-temp$se.fit
%           points(uvNorm$PosStd[keep],uvNorm$lRatio[keep],col=j,pch=16)
%           posFits<-unique(uvNorm[keep,c("variant","Exon","PosStd","adSmooth","adSmoothSE")])
%           lines(posFits$PosStd,posFits$adSmooth,col=j,lwd=5)
%           ##lines(posFits$PosStd,posFits$adSmooth + 2*posFits$adSmoothSE,
%           ##      col=j,lwd=3,lty=2)
%           ##lines(posFits$PosStd,posFits$adSmooth - 2*posFits$adSmoothSE,
%           ##      col=j,lwd=3,lty=2)
%           ## Add Effects Predictions to Full DB:
%           keep2<-((uvDB$Exon==uExon[i])&(uvDB$replicate==uRep[j]))
%           temp2<-predict(gam.pos,newdata=uvDB[keep2,],se.fit=TRUE)
%           uvDB$adSmooth[keep2]<-temp2$fit
%           uvDB$adSmoothSE[keep2]<-temp2$se.fit
%       }
%       legend("topright",inset=0.01,col=c(1:length(uRep)),lwd=5,legend=uRep)
%       
%   }
%   dev.off()
%% end.rcode

\newpage
\section{Exploratory Mixed Effects Model of The Labeled Data}

\subsection{Setup Data Structure}

The following code chunk creates the final analysis data set and adds
the positionally normalized, logged day 14 to day 0 rate ratio and the
exon by replicate batch variable.  This structure becomes the new data
base matrix {\texttt{uvDB}}.  This structure is used for this
section's exploratory analysis and for the final VarCall analysis.

%% begin.rcode, fig.width=6.5, fig.height=4.0
%  ## Positional Normalization for Day 0:
%  uvDB$offset[uvDB$day=="D0"]<-(uvDB$offset[uvDB$day=="D0"]/exp(uvDB$adSmooth[uvDB$day=="D0"]))
%  D0<-uvDB[uvDB$day=="D0",]
%  D0$ID<-paste0(D0$variant,"_",D0$replicate)
%  length(unique(D0$ID))
%  D14<-uvDB[uvDB$day=="D14",]
%  D14$ID<-paste0(D14$variant,"_",D14$replicate)
%  length(unique(D14$ID))
%  table(D14$ID %in% D0$ID)
%  table(D0$ID %in% D14$ID)
%  D0<-D0[D0$ID %in% D14$ID,]
%  table(D0$ID == D14$ID)
%  #########################################################################
%  ## This is the Normalized log(Ratio) Used in the Classification Model: ##
%  #########################################################################
%  D14$lRatio<-(log(D14$count) - log(D14$offset)) - (log(D0$count) - log(D0$offset))
%  hist(D14$lRatio,nclass=100,main="Log Ratio")
%  ############################################
%  ## Data Set for Analysis of Labeled Data: ##
%  ############################################
%  uvKnown<-D14[!is.na(D14$label),]
%  #################################
%  ## Data Set for Full Analysis: ##
%  #################################
%  uvDB<-D14
%  uvDB$ER<-factor(uvDB$ER)
%  uvDB$batch<-as.numeric(uvDB$ER)  ## More refined batch variable
%  table(uvDB$ER)
%  table(uvDB$batch)
%% end.rcode

\subsection{Mixed Effects Model for the Labeled Variants}

Here we fit a linear mixed model using the labeled variants.  The
model includes a fixed effect for pathogenicity status
(\texttt{label}) and (nested) random effects for variant and exon and
random intercept for label.

%% begin.rcode, fig.width=3.5, fig.height=4.0
%  lme.out2<-lme(lRatio ~ -1 + label, random= ~ -1+label|Exon/variant,data=uvKnown)
%  summary(lme.out2)
%  re<-ranef(lme.out2)
%  names(re)
%  names(re[[2]])
%% end.rcode

In the following code chunk, we check modeling assumptions.

%% begin.rcode, fig.width=7.5, fig.height=8.5
% par(mfrow=c(2,2))
%  qqnorm(re[["Exon"]][,1],main="Benign Exon Effects")
%  abline(a=0,b=sd((re[["Exon"]][,1])),lwd=2,col=2)
%  qqnorm(re[["Exon"]][,2],main="Pathogenic Exon Effects")
%  abline(a=0,b=sd((re[["Exon"]][,2])),lwd=2,col=2)
%  qqnorm(re[["variant"]][,1],main="Variant Effects")
%  abline(a=0,b=sd((re[["variant"]][,1])),lwd=2,col=2)
%  qqnorm(residuals(lme.out2),main="Replicate Effects (Residuals)")
%  abline(a=0,b=sd(residuals(lme.out2)),lwd=2,col=2)
%% end.rcode

Looks like a t--distribution with approximately five degrees of
freedom might be needed for the measurement model:

%% begin.rcode, fig.width=7.5, fig.height=8.5
%  par(mfrow=c(2,2))
%  q<-qt(p=((1:nrow(uvKnown) - 0.5)/nrow(uvKnown)),df=5)
%  emp.q<-sort(residuals(lme.out2))
%  plot(q,emp.q,main="5df T for Residuals")
%  abline(a=0,b=coef(lm(emp.q~-1+q)),lwd=2,col=2)
%  boxplot(residuals(lme.out2)~uvKnown$Exon,main="Residuals by Exon")
%  ##boxplot(residuals(lme.out2)~uvKnown$p.b,main="Residuals by Pathogenicity")
%  boxplot(residuals(lme.out2)~uvKnown$label,main="Residuals by Pathogenicity")
%  ##boxplot(residuals(lme.out2)~uvKnown$Exon + uvKnown$p.b,
%  ##        main="Residuals by Exon and Pathogenicity")
%% end.rcode



\section{Wrap--Up}

%% begin.rcode
%  MAYOuvDB<-uvDB
%  save(MAYOuvDB,file="mayoData.RData")
%  gc(); save.image()
%% end.rcode

\end{document}




%% begin.rcode, fig.width=6.5, fig.height=8.5
%% end.rcode


%% begin.rcode, fig.width=7.5, fig.height=3.5
%% end.rcode

%% begin.rcode, fig.width=6.5, fig.height=8.0
%% end.rcode

%% begin.rcode, fig.width=3.5, fig.height=4.0
%% end.rcode

%% begin.rcode, fig.width=7.5, fig.height=8.5
% par(mfrow=c(2,2))
%% end.rcode

%% begin.rcode, fig.width=7.5, fig.height=8.5
% par(mfrow=c(2,2))
%% end.rcode

% end.rcode
